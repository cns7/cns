Exercise 1 : 
	To create a calculator server - 
	1. 	new project -> Java Web -> Web Application 
	2. 	new web service -> give package name
		go to design -> add module ...
	3.	Deploy
	4.	Run (Browser will open up)
		In this browser add /'name of your WebService'?Tester (Remember T is caps)
		eg localhost:8080/TestCalculator/CalculatorWebService?Tester
	To create a calculator client - 
	1.	new project -> Java Web -> Web Application
	2. 	new Java web client 
		Here give the WSDL url 
		Get the wsdl from the previous step 4 as given below
		localhost:8080/TestCalculator/CalculatorWebService?WSDL
		Add a package name as something like com.calculatorClient.example
	3. 	In the Webpages folder add jsp files 
		a. 	index.jsp
			Have a form with action = 'arithmetic.jsp' method = 'get'
			Have input in this form name = 'num1' type = 'number'
			Have input in this form name = 'num2' type = 'number'
			input type = 'submit' name = 'submit' value = 'add'
		b.	arithmetic.jsp
			within <% %> type the below given codes 
			com.package_of_client.example.server_service service = new com.package_of_client.example.server_service()
			com.package_of_client.example.server port = service.(autofill)

			now write the required java code
			To convert String to integer use Integer.parseInt(String)
			i.e. int num1 = Integer.parseInt(request.getParameter("num1"));
			only in the return statement use result = port.add(num1,num2);
			out.println(result)

Exercise 2 : 
	New project->Java->Java class library
	Right click on pjt->new->Axis web service
	tick the checkbox wsdl
	class name->package name
	type the code
	
	Rightclick pjt->build
	Files->doc->netbeansprojects->projectname->build->axis2->web-inf->services->newaxis.arr->extract->MetaINF->services.xml->Change 2004/08 to ns
	
	Target location la war file path
	Netbeans->tools->options->type the url in google

	http://localhost:8080/axis2
	login usrname and pwd:admin,axis2
	Viewservices ->ourservices->a url will be displayed
	delete till ?WSDL then /<functionname>?parametername1=value1&parametername2=value2
	


Exercise 3 & 4 & 5 : 
	EX 3
	> sudo apt-get install default-jdk
	>java -version
	>file.java
		import java.io.*;
		class file
		{
			public static void main(String[] args)
			{
				System.out.println("HIIII");
			}
		}
	>javac file.java
	>java file

	EX 4
	For ssh, scp, etc
	Create two VMs and their network settings must be bridged adapter with Allow all
	Their respective iPv4 addresses are 
	address : 10.6.15.(system number + 100) && 10.6.15.(system number + 150) 
	{to be safe, try ipconfig in windows and see if the IP, first 3 numbers are similar}
	netmask : 255.255.128.0
	gateway : 10.6.0.1
	DNS :	  10.101.1.10
	In both Vms,
	> sudo apt-get update
	> sudo apt-get install openssh-server

	Remote login with password
	Now try - 
		>ssh -X usernameVM1@ipofVM1
		>scp file1.txt usernameVM1@ipofVM1:/home/username/

	(if this doesnt work -
	> sudo apt-get update 
	> sudo ufw allow 22 
	then try again)

	
	for remote login without password 
	In VM2,
	> ssh-keygen -t rsa
	> cd ~/.ssh
	> ls
	> chmod 700 id_rsa.pub
	> cp id_rsa.pub known_hosts
	>cd\
	> ssh-copy-id usernameVM1@ipofVM1
	
	

Exercise 6 : 
	CLOUD CONTROLLER
	For this install cloud controller first 
	keyboard interupt NO
	iP - 10.6.15.(100 + system number)
	username cloudcontroller
	clustername cluster1
	For range of iPs, just copy the example given
	Tick everyting other than node controller 

	NODE CONTROLLER 
	iP - 10.6.15.(system number + 150)
	Tick only node controller

	CLIENT
	Here the client system must not have its proxy set 
	not sure about manual ip setting, (try without and with)
	Now to access the eucalyptus page in the browser 
	type in
	https://ip_of_cloudcontroller:8443
	Username and password : admin
	download the credentials 
	scp (filename).zip clodcontroller@(ipaddress):/home/cloudcontroller

	In CLOUD CONTROLLER
	now create a secret directory 
	> mkdir -p ~/.euca
	> cd (~/.)euca
	> chmod 700 ~/.euca
	>(chmod 600 ~/.euca/*)
	> sudo euca_conf --get-credentials (anyname).zip
	>unzip (anyname).zip

	In the CLIENT 
	> sudo apt-get update
	> sudo apt-get install euca2ools
	> (unzip (anyname).zip)
	Open the eucarc file and note down ec2_URL, ec2_accessKey and ec2_secretkey
	> euca-create-volume -U ec2_URL -I ec2_accessKey -S ec2_secretKey --size 1 -z cluster1
	> euca-describe-volumes -U ec2_URL -I ec2_accessKey -S ec2_secretKey

Exercise 7 : OpenNebula

	Create two virtual machines VM1 and VM2. 
	Switch to Main server in software and updates settings
	in VM1 
	shift to the root by doing 
	> sudo -i
	then execute the following commands - 
	> sudo apt-get update
	> wget -q -O- https://downloads.opennebula.org/repo/repo.key | apt-key add -
	> sudo apt-get update
	> apt-get install opennebula opennebula-sunstone opennebula-gate opennebula-flow
	> ((sudo) /usr/share/one/install_gems)
	> (sudo) gedit /var/lib/one/.one/one_auth
	This will give you the password
	shift to oneadmin
	> su oneadmin
	> systemctl start opennebula
	> systemctl start opennebula-sunstone
	now go to browser and type
	localhost:9869
	login with 
	user : oneadmin
	password : that obtained from one_auth file

	in VM2
	shift to the root by doing 
	> sudo -i
	then execute the following commands - 
	> sudo apt-get update
	> wget -q -O- https://downloads.opennebula.org/repo/repo.key | apt-key add -
	> sudo apt-get update
	> sudo apt-get install opennebula-node
	> sudo service libvirt-bin restart

Exercise 8 :
	shift to root
	> sudo -i
	shift to oneadmin
	> su oneadmin
	> onehost list 
	> onevnet list
	> oneimage list
	> onetemplate list
	> onevm list
	
	In dashboard,
	
		host->create host
		infrastructure->virtual network->add->name=private(general) || bridge=br0(conf) || ip=192...(address) || size = 100(address)->create
		(thank me later)
		virtual resources -> images->add->name->advanced options->drivers->qcow2->path:"/home"
		vr->template(vcpu=1)(general) storage->add another disk network os_booting=x86_64 i/o vnc
		get ssh key to paste it in the user settings
		> cat /var/lib/one/.ssh/id_rsa.pub 
		IN DASHBOARD,oneadmin->settings->public ssh key (paste)
		template->select->instantiate
		vr->virtual machine
	

	
Exercise 9 : 
	After doing the steps of excercise 8, create another host, enable both of them
	> onevm deploy <vm-id> <host-id>
	> onevm migrate <vm-id> <host-id>




Exercise 10 :

Moving tar file from z to shared folder
Devices->shared folder->settings->(path of the file)->checkbox
in the vm,terminal la
>sudo apt-get install virtualbox-guest-utils
>mkdir GUEST_SHARE
>sudo mount -t vboxsf (nameofthefolderinwindows) GUEST_SHARE
>sudo adduser (vmname) vboxsf

sudo apt-get install default-jdk

sudo adduser hduser
sudo usermod -G sudo hduser
su hduser

sudo apt-get install openssh-server
ssh-keygen -t rsa -p '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa >> ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/id_rsa
ssh localhost

sudo tar xfz hadoop_tar_file
sudo mv hadoop_2.7.7 /usr/local/hadoop

sudo nano /usr/local/hadoop/etc/hadoop/hadoop-env.sh
* Identify the below line & set below path
export JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64"

sudo nano ~/.bashrc
export JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64"
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=$JAVA_HOME/lib

#HADOOP VARIABLES START
export HADOOP_INSTALL=/usr/local/hadoop
export PATH=$PATH:$HADOOP_INSTALL/bin
export PATH=$PATH:$HADOOP_INSTALL/sbin
export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_HOME=$HADOOP_INSTALL
export HADOOP_HDFS_HOME=$HADOOP_INSTALL
export YARN_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/native export HADOOP_OPTS=“-Djava.library.path=$HADOOP_HOME/lib”
export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jar
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
#HADOOP VARIABLES END

source ~/.bashrc

sudo nano /usr/local/hadoop/etc/hadoop/core-site.xml
<property>
<name>fs.default.name</name>
<value>hdfs://localhost:9000</value>
</property>

sudo nano /usr/local/hadoop/etc/hadoop/yarn-site.xml
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
<property>
<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
<value>org.apache.hadoop.mapred.Shufflehandler</value>
</property>

* If mapred-site.xml file not found,
sudo cp mapred-site.xml.template mapred-site.xml
sudo nano /usr/local/hadoop/etc/hadoop/mapred-site.xml
<property>
<name>mapreduce.framework.name</name>
<value>yarn</yarn>
<property>

sudo mkdir -p /usr/local/hadoop_store/hdfs

sudo nano /usr/local/hadoop/etc/hadoop/hdfs-site.xml
<property>
<name>dfs.replication</name>
<value>1</value>
<property>
<property>
<name>dfs.namenode.name.dir</name>
<value>file:/usr/local/hadoop_store/hdfs/namenode</value>
<property>
<property>
<name>dfs.datanode.data.dir</name>
<value>file:/usr/local/hadoop_store/hdfs/datanode</value>
<property>

sudo chown hduser:hduser -R /usr/local/hadoop
sudo chown hduser:hduser -R /usr/local/hadoop_store
sudo chmod -R 777 /usr/local/hadoop
sudo chmod -R 777 /usr/local/hadoop_store

/usr/local/hadoop/bin/hadoop namenode -format
bash /usr/local/hadoop/sbin/start-all.sh
jps

* Type below url in browser.
http://localhost:8088

* Type some content in newly created file.
sudo nano input.txt

hdfs dfs -mkdir -p /user/hadoop/inputfiles
hdfs dfs -put input.txt /user/hadoop/inputfiles
hdfs dfs -ls /user/hadoop/inputfiles

---------------------
* WordCount.java

import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {

  public static class TokenizerMapper
       extends Mapper<Object, Text, Text, IntWritable>{

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context
                    ) throws IOException, InterruptedException {
      StringTokenizer itr = new StringTokenizer(value.toString());
      while (itr.hasMoreTokens()) {
        word.set(itr.nextToken());
        context.write(word, one);
      }
    }
  }

  public static class IntSumReducer
       extends Reducer<Text,IntWritable,Text,IntWritable> {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable<IntWritable> values,
                       Context context
                       ) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      result.set(sum);
      context.write(key, result);
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf, "word count");
    job.setJarByClass(WordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}

---------------------

/usr/local/hadoop/bin/hadoop com.sun.tools.javac.Main WordCount.java
jar cf wc.jar WordCount*.class
ls
/usr/local/hadoop/bin/hadoop jar wc.jar WordCount /user/hadoop/inputfiles /user/hadoop/outputfiles
hdfs dfs -ls /user/hadoop/outputfiles
hdfs dfs -cat /user/hadoop/outputfiles/part-r-00000

--------------------------------------------------------------
# Ex 11: Hadoop fuse

wget https://archive.cloudera.com/cdh5/one-click-install/trusty/amd64/cdh5-repository_1.0_all.deb
sudo dpkg -i cdh5-repository_1.0_all.deb
sudo apt-get update 
sudo apt-get install hadoop-hdfs-fuse
sudo mkdir -p /mnt/hdfs
hadoop-fuse-dfs dfs://localhost:50070 /mnt/hdfs

--------------------------------------------------------------
# Helpline (If any error occurs in above steps, refer below)

# Ex 3-5

sudo add-apt-repository ppa:webupd8team/java
sudo apt-get install openjdk-8-jre
sudo apt-get install openjdk-8-jdk
sudo apt-get install openssh-server openssh-client
